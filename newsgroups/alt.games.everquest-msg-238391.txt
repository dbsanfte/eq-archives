From -6532238096800941173
X-Google-Language: ENGLISH,ASCII-7-bit
X-Google-Thread: fb739,e4aec4e1e225ac6c
X-Google-Attributes: gidfb739,public
X-Google-ArrivalTime: 2004-03-05 09:23:01 PST
Path: archiver1.google.com!news2.google.com!newsfeed2.dallas1.level3.net!news.level3.com!zeus.visi.com!news-out.visi.com!petbe.visi.com!news.octanews.net!feed5.newsreader.com!newsreader.com!news3.optonline.net!news4.srv.hcvlny.cv.net.POSTED!not-for-mail
From: "Chris Monster" <noloveforspam@hotmail.com>
Newsgroups: alt.games.everquest
References: <4041f4c7$0$155$a1866201@newsreader.visi.com> <f3j440tqmsae5jgduhiihdcso2knaaoi1f@4ax.com> <404274a4$0$41290$a1866201@newsreader.visi.com> <evl54057uhta1cg8v785g3depncbun5b5n@4ax.com> <40433d48$0$41290$a1866201@newsreader.visi.com> <2vj640tpb8cq2o26dvl2of3vk0ikjn0op9@4ax.com> <aUL0c.14129$yZ1.13441@newsread2.news.pas.earthlink.net> <XNL1c.73255$A12.71873@edtnps84>
Subject: Re: Mind? (was Re: God and Free Will)
Lines: 176
X-Priority: 3
X-MSMail-Priority: Normal
X-Newsreader: Microsoft Outlook Express 6.00.2800.1158
X-MimeOLE: Produced By Microsoft MimeOLE V6.00.2800.1165
Message-ID: <_y22c.14642$UF1.1664448@news4.srv.hcvlny.cv.net>
Date: Fri, 05 Mar 2004 17:13:30 GMT
NNTP-Posting-Host: 24.45.56.240
X-Complaints-To: abuse@cv.net
X-Trace: news4.srv.hcvlny.cv.net 1078506810 24.45.56.240 (Fri, 05 Mar 2004 12:13:30 EST)
NNTP-Posting-Date: Fri, 05 Mar 2004 12:13:30 EST
Organization: Optimum Online
Xref: archiver1.google.com alt.games.everquest:22362


"Ken Andrews" <gobble@degook.com> wrote in message
news:XNL1c.73255$A12.71873@edtnps84...
> "Tim Smith" <reply_in_group@mouse-potato.com> wrote
> > In article <2vj640tpb8cq2o26dvl2of3vk0ikjn0op9@4ax.com>, 42 wrote:
> > > Theres a common thought experiment that has uses synthetic neurons...
> > ...
> > > Then we replace another one... and we ask ourselves... is it still a
> > > conscious human mind... and we repeat it, one neuron at a time...
> > ...
> > > And there are 2 general outcomes: (and a few unlikely exotic ones)
> > > 1) That the mind will gradually lose consciousness as neurons are
> > > replaced. (not necessarily on a linear scale, but in some proportion
> > > to the amount of sythetic replacement.
> > >
> > > or
> > > 2) That the mind will continue to function as before, unaware that it
> > > was ever rebuilt.
> >
> > As you say in the part I trimmed, most people expect the outcome would
be
> > #2.  However, I think the more interesting question is to assume #2, and
> ask
> > whether the mind at the end is the *same* mind you started with, or a
new
> > mind that *thinks* it is the same one.
> >
> > Let's assume that the artificial neurons last longer than natural
neurons,
> > so that there is an advantage to having them...then the question is
would
> > you want to undergo this procedure?
>
> Yes.
>
>
> > If the minds are the same mind, then sure I would.  A brain that won't
> > gradually go senile from neuron loss would be great--and if we had the
> > technology for these things, we'd probably have licked the artificial
> organ
> > problem for the rest, too, and so basically this would be immortality.
> >
> > However, if it is creating a new mind with my memories that thinks it is
> me,
> > then no thanks--I'm not sacrificing myself so that society can have the
> > benefit of an immortal copy of me.
>
> Also agree.
>
>
> > Looking at it another way...suppose it were possible to stop a brain and
> > take it apart, mapping out how every neuron is connected to every other
> > neuron.  From that map, you could build another brain, using the
> artificial
> > neurons.  Suppose you built that other brain in the body you had removed
> the
> > model brain from.  You then turn on the artificial brain, and it starts
> > running, at the point where the natural brain had been shut down.
> >
> > I think most people would agree that a murder or at least suicide has
> taken
> > place here--the new brain has a new mind, and the original was killed.
> The
> > question then is how is this any different from your experiment?  Does
it
> > really make a difference that the replacement happened one step at a
time?
> > In both cases, we basically take all the brain cells out of someone's
head
> > and put in artificial cells in the same configuration.
>
> Yes, actually, it does matter whether it's done all at once versus over
> time.  In reality your brain (and the rest of your body) is doing the
> switch-over-time operation.  Old connections disappear, new ones appear,
and
> you gradually lose / gain memories, habits, and opinions.  We don't view
> this gradual modification as abnormal or the creation of a "new" person;
we
> rather view it as aging and experience.  (Case in point, what was your
view
> of girls when you were 6?  How does it differ from your view now?)
>
>
> > Similar questions can be raised about transporters in stories where they
> > work by scanning your complete state and sending that to the
destination,
> > where they construct a copy of you there.  As far as I'm concerned,
those
> > transporters don't take you anywhere--they kill you at the source, and
> > construct an exact copy at the destination.  No thanks...I'll walk. :-)
>
> Fully agree.  Fun thing about the Star Trek transporter is that they keep
on
> viewing it as sort of a meld of the two, and sometimes they contradict
> themselves because of it.
>
>
> > I have a friend who agrees that such a transporter does indeed work by
> > kill-and-copy, but would ride them anyway.  As long as what comes out
the
> > other end is indistinguishable from him to his wife and kids and
society,
> he
> > says what does it matter if he dies?  No one can measure any loss.  I
find
> > this to be a very weird way to look at things.
>
> I'm gonna live forever or die trying.  Giving everybody else a
> just-as-good-as-the-original copy isn't my idea of success.
>
>
> > And what happens if the "kill" part malfunctions, so you walk out of
> source
> > booth complaining that you didn't go anywhere, AND your copy walks out
of
> > the destination booth, thinking all went well?  Which one gets your
spouse
> > and stuff?
>
> Ask Will Ryker in ST:TNG.
>
>
> > One could write a nasty story about this kind of transporter...suppose
the
> > "kill" function is not automatic.  You hit the "go" button, you are
> scanned
> > non-destructively, the copy is made, and then when confirmation comes
> back,
> > you get zapped (not just to avoid thorny legal issues, BTW, but also to
> > provide raw material to construct incoming passengers).  Perhaps late at
> > night, sadistic, bored, transport operators might disable the kill
> function,
> > and play with the transportees...killing them manually, after using them
> for
> > whatever sick entertainment they enjoy.  There could be a whole
> underground
> > in sex slaves and gladiator contests and stuff using transportees.  I
> think
> > there's room for a pretty disturbing and memorable story in there...any
of
> > you that are writers, feel free to write it!
>
> Too late, by about 20 years.  A short story was written quite a while ago
> covering that exact thing.  People were knocked out, scanned, the
duplicate
> created at the target site, and then they killed the originals.  Alas,
I've
> forgotten who wrote it or what it was called.
>
> One of the problems demonstrated was data density.  They were trying to
send
> a fat Senator.  They normally sent people head-first, but kept on running
> out of storage space as they couldn't send the information fast enough to
> get the torso finished before it started processing the legs.  This wound
up
> with several failures, leaving half-corpses at the receiving end.  They
> finally decided to swap ends and send him feet-first.  When they got
bogged
> down on transmission of the torso, they only had the head and shoulders
left
> to scan, and had enough room to store the information.
>
> Subsequently, one of the operators who'd been having attacks of conscience
> woke the sending-end Senator and showed him the television view of "him"
> talking to people at the other end.  He also tattled on other operators
who
> would send women, then wake the sending-end woman, have sex with her, then
> kill her.
>
> I've gotta find that story again.  It's been, oh, at least 15 years since
I
> read it.
>
>




