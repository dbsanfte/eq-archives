From 3426287674912881731
X-Google-Language: ENGLISH,ASCII-7-bit
X-Google-Thread: fb739,8799123873439500
X-Google-Attributes: gidfb739,public
X-Google-ArrivalTime: 2003-11-06 23:56:17 PST
Path: archiver1.google.com!news2.google.com!news.maxwell.syr.edu!elnk-pas-nf1!newsfeed.earthlink.net!pd7cy1no!shaw.ca!pd7tw3no.POSTED!53ab2750!not-for-mail
X-Trace-PostClient-IP: 24.81.150.191
From: 42 <user@example.net>
User-Agent: Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.4) Gecko/20030624
X-Accept-Language: en-us, en
MIME-Version: 1.0
Newsgroups: alt.games.everquest
Subject: Re: OT: Morality
References: <3FA282F0.9DEED111@dejazzd.com> <wqHpb.285870$6C4.211095@pd7tw1no> <bocasr$4m$1@woodrow.ucdavis.edu> <JKiqb.313766$pl3.272186@pd7tw3no> <boempo$hq6$1@woodrow.ucdavis.edu>
In-Reply-To: <boempo$hq6$1@woodrow.ucdavis.edu>
Content-Type: text/plain; charset=us-ascii; format=flowed
Content-Transfer-Encoding: 7bit
Lines: 123
Message-ID: <AeIqb.329687$pl3.218699@pd7tw3no>
Date: Fri, 07 Nov 2003 07:56:16 GMT
NNTP-Posting-Host: 24.69.255.206
X-Complaints-To: abuse@shaw.ca
X-Trace: pd7tw3no 1068191776 24.69.255.206 (Fri, 07 Nov 2003 00:56:16 MST)
NNTP-Posting-Date: Fri, 07 Nov 2003 00:56:16 MST
Organization: Shaw Residential Internet
Xref: archiver1.google.com alt.games.everquest:6302

Remington Stone wrote:

> 42  said:
> }> Hmm, I think you've identified the difference between the Christian 
> }> version and Kant's version.  The difference is the Christian version says, 
> }> "You should kill others if you want them to kill you".  Kant's version 
> }> says "You should kill others if you want them to kill you and you don't 
> }> care what happens to everyone else".  Still, in either case, it's possible 
> }> for someone to be psycho enough that the statement is exhorting them to 
> }> random murder.
> }Nobody ever asserted that we should be calibrating our moral compass 
> }with psychotics. Its almost self-evident that any moral guidelines that 
> }you derive from what insane sociopaths think is going to be pretty 
> }questionable.
> 
> I'm not suggesting that we derive moral guidelines from how psychos think.  
> I'm suggesting that a moral guideline that doesn't take into account that 
> we don't all think the same is not perfect.  I will not assert that we 
> should calibrate our moral compass -with- psychotics, but that a moral 
> compass that is not calibrated so that even psychos can use it is less 
> than ideal.
> 
> Statistics show that one in four folks will be diagnosed with some sort of 
> mental disorder in their lifetime, don't they?  How good is a Golden Rule 
> that only works for 3 people in 4?  Sure, the other 25% may not be crazy 
> in that exactway, but there is probably some point (and probably a less 
> dramatic one) where their desires will differ from the desires of those 
> their actions affect.  Which is all that is required for the rule to go a 
> bit haywire, isn't it?

I would be 'happy' to assert that we should only consider rational sane 
peoples opinions. Unfortunately, I would not dare to presume to try and 
judge who is sane and rational. :)

> }> }> It's a funny old world, isn't it?  I do like the axiom, but it's not 
> }> }> -quite- perfect, somehow.
> }> }The maxim presupposes a generous helping of self-interest. It is not in 
> }> }anybodies self interest to wipe everyone out.
> }> No, it's not really self-interest.  If you're suicidal and too chicken to 
> }> do it yourself, it's arguably in your self-interest to convnce others to 
> }> kill you.  
> }Terrible example. That is a far cry from thinking that everybody should 
> }be killed. Your just making some sort of right to suicide argument, 
> }which is far far less controversial than advocating mass slaughter on 
> }all sides.
> 
> No, that's not quite what I'm doing.  I'm suggesting that there are those 
> for whom the Golden Rule would be an incitement to mass slaughter rather 
> than a prohibition against it.  And in this particular part, I'm debating 
> your use of the term self-interest as opposed to self-preservation, which 
> seems closer to what you probably meant.
> 
> The neat thing is, the original example I gave also works backward.  
> Assume for a moment you're a doctor.  A doctor who believes very, very, 
> strongly that life should be preserved in all instances.  Perhaps a doctor 
> who believes that there is no afterlife or reincarnation or -anything- 
> after death.  In any case, one who believes that in any instance where 
> life can be prolonged, it should be, which is, of course, a universal 
> rule, in keeping with Kant's version.  Now assume you have a patient in a 
> coma who will (probably) never recover, and who may well be suffering 
> greatly in this coma, you have no way of knowing.  And assume the 
> patient has left a living will saying he wants to be unplugged should 
> those circumstances ever occur.  The Golden Rule says very clearly that 
> you should not unplug this patient, since that's what -you- would want, 
> isn't it?  But is that morally right, given the patient's express wish?

You introduced a 3rd 'aspect' that you never evaluated... the 'patient's 
express wish' ... how much value does each person attach to that 
according to the 'golden rule'? The right to self-destiny is surely 
something even the preservationist doctor would see value in, because he 
surely doesn't wish to lose that right for himself... and this is in 
direct conflict with his preservationist desires in this case... and 
thus a true moral dilemma occurs... where 2 DESIRABLE moral maxims conflict.

Sorting that one out is a completely separate debate.

> Assume person A likes being patted on the head, and sees no reason anyone 
> else would mind it, and person B doesn't like it because it reminds him of 
> his annoying uncle.  The rule tells person A to pat person B on the head 
> anyway, no matter how person B feels about it.  At least until person B 
> slugs him in the arm and explains why. :)

Again your selectively applying the rule. Person A should consider that 
he's annoying person B, and would surely not wish all the person B's in 
the world to annoy him, just so he could pat them on their heads. This 
2nd maxim would conflict against the first (that being how wonderful it 
is to pat heads) and person would almost certainly determine that living 
in a world where everybody else isn't pissing him off would beat the 
minor enjoyment he'd derive from patting this guys head.
> 
> Assume person A would always want help with a mob he's soloing if he were 
> under 10% health and the mob's over 90%, because, say, he's a lowbie 
> rogue.  The rule then expressly tells him to go save that soloing necro 
> over there, doesn't it?  (This one might get a little less likely with the 
> Kant version, if we assume the lowbie rogue's ever played other classes.)

Oooh... back on topic :)



> But the ultimate point is, the Golden Rule there (ether version) doesn't 
> incorporate any notion of people having differing desires in regards to 
> how they are treated, and given the great diversity in how people wish to 
> be treated, it might be worth considering an amendment. 

But it does. You just need to get more abstract. The maxim: 'try not to 
annoy other people, hurt them, and get in their way!' is fully supported 
by Kant's axiom. We'd all like other people to try not to annoy us, hurt 
us, and get in our way...

'Respect other people desires' is acutally a result of the axiom. 
Because we want our desires respected, and to the extent that someone 
elses desires do not negatively impact on us then that becomes a 'good' 
maxim.

  It's still a
> pretty darn good rule, though, I won't argue that.  I also won't argue 
> that Kant's version is an improvement over the original, but perhaps not 
> quite the right improvement.

I think there are more consequences of Kant's axiom than you've 
previously considered.



