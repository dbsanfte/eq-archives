{"ygPerms":{"resourceCapabilityList":[{"resourceType":"GROUP","capabilities":[{"name":"READ"},{"name":"JOIN"}]},{"resourceType":"PHOTO","capabilities":[]},{"resourceType":"FILE","capabilities":[]},{"resourceType":"MEMBER","capabilities":[]},{"resourceType":"LINK","capabilities":[]},{"resourceType":"CALENDAR","capabilities":[]},{"resourceType":"DATABASE","capabilities":[]},{"resourceType":"POLL","capabilities":[]},{"resourceType":"MESSAGE","capabilities":[{"name":"READ"}]},{"resourceType":"PENDING_MESSAGE","capabilities":[]},{"resourceType":"ATTACHMENTS","capabilities":[{"name":"READ"}]},{"resourceType":"PHOTOMATIC_ALBUMS","capabilities":[]},{"resourceType":"MEMBERSHIP_TYPE","capabilities":[]},{"resourceType":"POST","capabilities":[{"name":"READ"}]},{"resourceType":"PIN","capabilities":[]}],"groupUrl":"groups.yahoo.com","intlCode":"us"},"comscore":"pageview_candidate","ygData":{"userId":80423493,"authorName":"bigmaca3","from":"&quot;bigmaca3&quot; &lt;bigmaca3@...&gt;","profile":"bigmaca3","replyTo":"LIST","senderId":"GV1sN6dkNZT0lax0iQHfiNkAVjCODamHK0L_MbHgAXQq2XxQDNxtcNmXv_aMI9BgO2zmBajEEAVL3h3KeNL3boB5nHIAwg","spamInfo":{"isSpam":false,"reason":"0"},"subject":"Re: Geforce 4 MX vs Geforce 4 Ti","postDate":"1019085501","msgId":2728,"canDelete":false,"contentTrasformed":false,"systemMessage":false,"headers":{"messageIdInHeader":"PGE5a3ZydCtnMGJzQGVHcm91cHMuY29tPg==","inReplyToHeader":"PE9FMTY3R0xDV1pxZ0Fiek9CVG0wMDAwMDQ4ZUBob3RtYWlsLmNvbT4="},"prevInTopic":2722,"nextInTopic":2729,"prevInTime":2727,"nextInTime":2729,"topicId":2716,"numMessagesInTopic":22,"msgSnippet":"... GeForce2 chip with its simple T&L engine, a second RAMDAC for DualDisplay functionality (nView), a watered-down version of the LightSpeed Memory","messageBody":"<div id=\"ygrps-yiv-1245382659\">--- In EverQuest@y..., &quot;J. Smythe&quot; &lt;lgumaer@h...&gt; wrote:<br/>\n<blockquote><span title=\"ireply\"> &gt; From tomshardware.com<br/>\n&gt; <br/>\n&gt;  This makes sense, since the GeForce4 MX is basically only a <br/>\n </span></blockquote>GeForce2 chip with its simple T&L engine, a second RAMDAC for <br/>\nDualDisplay functionality (nView), a watered-down version of <br/>\nthe &#39;LightSpeed Memory Architecture II&#39; and an AccuView FSAA unit <br/>\nadded onto it. However, it does not have the DirectX 8 capable pixel <br/>\nand vertex shaders of the GeForce4 Ti and the GeForce3 families. <br/>\n<br/>\nI have a Geforce 2Ti and the change from my Geforce 256 was amazing.  <br/>\nPeople are amazed that the clouds look like clouds now.  I plan on <br/>\ngetting the Geforce 4 as soon as the proce drops a bit more.<br/>\n<br/>\nAnd I have no Direct X issues.</div>","specialLinks":[]}}